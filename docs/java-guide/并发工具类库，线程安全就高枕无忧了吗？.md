## 并发工具类库，线程安全就高枕无忧了吗？
::: tip 
 并发工具包括`同步器`和`容器`两大类

 接下来，我们就看看在使用并发工具时，最常遇到哪些坑，以及如何解决、避免这些坑
::: 
### ThreadLocal使用过程中,线程重用导致用户信息错乱的Bug
::: tip
 ThreadLocal:

 线程本地变量或线程本地存储，让每个`线程有自己`”`独立`“的`变量副本`，线程之间互不影响。它为每个线程都创建一个副本，每个`线程`可以`访问自己内部`的`副本变量`

 我们都知道`ThreadLocal`适用于变量在线程间隔离，而在方法或类间共享的场景
::: 
#### 场景重现

使用 Spring Boot 创建一个 Web 应用程序，使用 ThreadLocal 存放一个 Integer 的值，来暂且代表需要在线程中保存的用户信息，这个值初始是 null。

在业务逻辑中，我先从 `ThreadLocal` 获取一次值，然后把外部传入的参数设置到 `ThreadLocal` 中，来模拟从当前上下文获取到用户信息的逻辑，随后再获取一次值，最后输出两次获得的值和线程名称。

```java
/**
 * @author zln
 * @date 2021-11-26
 */
@RestController
public class ThreadLocalTestController {


    /**
     * Lambda构造方式
     *  //相当于以下代码
     *  ThreadLocal<Integer> currentUser = new ThreadLocal<>();
     *  currentUser.set(null);
     * */
    private static final ThreadLocal<Integer> currentUser = ThreadLocal.withInitial(() -> null);


    @GetMapping("wrong")
    protected Map wrong(@RequestParam("userId") Integer userId) {
        //设置用户信息之前先查询一次ThreadLocal中的用户信息
        String before  = Thread.currentThread().getName() + ":" + currentUser.get();
        //设置用户信息到ThreadLocal
        currentUser.set(userId);
        //设置用户信息之后再查询一次ThreadLocal中的用户信息
        String after  = Thread.currentThread().getName() + ":" + currentUser.get();
        //汇总输出两次查询结果
        Map result = new HashMap(16);
        result.put("before", before);
        result.put("after", after);
        return result;
    }

}
```

```json
--- 分别使用10，20，30测试结果如下
{
    "before": "http-nio-8080-exec-9:null",
    "after": "http-nio-8080-exec-9:10"
}

{
    "before": "http-nio-8080-exec-2:null",
    "after": "http-nio-8080-exec-2:20"
}

{
    "before": "http-nio-8080-exec-3:null",
    "after": "http-nio-8080-exec-3:30"
}
```
::: tip
 按理说，在设置用户信息之前第一次获取的值`始终应该`是null

 这里我们看一下符合预期。

 但我们要意识到，程序运行在 Tomcat 中，执行程序的线程是 Tomcat 的工作线程，而 Tomcat 的工作线程是`基于线程池`的。

 一旦线程重用，那么很可能首次从 ThreadLocal 获取的值是之前其他用户的请求遗留的值

 为了更快地重现这个问题,我们把tomcat工作线程设置为1，在测试一下

 我这里使用的springboot只需要

 application.properties 添加  `server.tomcat.threads.max=1`

 如果是外部tomcat 添加 `server.tomcat.max-threads=1`
::: 
```bash
--- 同样分别使用10，20，30测试结果如下
{
    "before": "http-nio-8080-exec-1:null",
    "after": "http-nio-8080-exec-1:10"
}

{
    "before": "http-nio-8080-exec-1:10",
    "after": "http-nio-8080-exec-1:20"
}

{
    "before": "http-nio-8080-exec-1:20",
    "after": "http-nio-8080-exec-1:30"
}
```
::: tip
 原因就是 Tomcat 的线程池重用了线程

 这个例子告诉我们，在写业务代码时，首先要理解代码会跑在什么线程上

 因为线程的创建比较昂贵，所以 Web 服务器往往会使用`线程池`来处理请求，这就意味着`线程会被重用`
::: 
#### 总结

用类似 ThreadLocal 工具来存放一些数据时，需要特别注意在代码运行完后，`显式地去清空设置的数据`

```java
    @GetMapping("nowrong")
    protected Map nowrong(@RequestParam("userId") Integer userId) {
        //设置用户信息之前先查询一次ThreadLocal中的用户信息
        String before  = Thread.currentThread().getName() + ":" + currentUser.get();
        //设置用户信息到ThreadLocal
        currentUser.set(userId);
        try {
            //设置用户信息之后再查询一次ThreadLocal中的用户信息
            String after  = Thread.currentThread().getName() + ":" + currentUser.get();
            //汇总输出两次查询结果
            Map result = new HashMap(16);
            result.put("before", before);
            result.put("after", after);
            return result;
        }finally {
            currentUser.remove();
        }
    }
```

### 使用了线程安全的并发工具，并不代表解决了所有线程安全问题
::: tip
ConcurrentHashMap，是一个高性能的线程安全的哈希表容器，只能保证提供的`原子性读写操作`是`线程安全`的。
::: 
#### 场景重现

有一个含 900 个元素的 Map，现在再补充 100 个元素进去，这个补充操作由 10 个线程并发进行。

开发人员误以为使用了 ConcurrentHashMap 就不会有线程安全问题，于是不加思索地写出了下面的代码：

在每一个线程的代码逻辑中先通过 size 方法拿到当前元素数量，计算 ConcurrentHashMap 目前还需要补充多少元素，并在日志中输出了这个值，然后通过 putAll 方法把缺少的元素添加进去。

```bash
2021-11-26 16:20:12.378  INFO 16612 --- [io-8080-exec-10] .z.j.c.c.ConcurrentHashMapTestController : init size:900
2021-11-26 16:20:12.379  INFO 16612 --- [Pool-5-worker-9] .z.j.c.c.ConcurrentHashMapTestController : gap size:100
2021-11-26 16:20:12.380  INFO 16612 --- [Pool-5-worker-2] .z.j.c.c.ConcurrentHashMapTestController : gap size:100
2021-11-26 16:20:12.380  INFO 16612 --- [ool-5-worker-11] .z.j.c.c.ConcurrentHashMapTestController : gap size:100
2021-11-26 16:20:12.380  INFO 16612 --- [Pool-5-worker-4] .z.j.c.c.ConcurrentHashMapTestController : gap size:100
2021-11-26 16:20:12.380  INFO 16612 --- [Pool-5-worker-2] .z.j.c.c.ConcurrentHashMapTestController : gap size:-100
2021-11-26 16:20:12.381  INFO 16612 --- [Pool-5-worker-4] .z.j.c.c.ConcurrentHashMapTestController : gap size:-100
2021-11-26 16:20:12.381  INFO 16612 --- [Pool-5-worker-2] .z.j.c.c.ConcurrentHashMapTestController : gap size:-100
2021-11-26 16:20:12.380  INFO 16612 --- [ool-5-worker-13] .z.j.c.c.ConcurrentHashMapTestController : gap size:100
2021-11-26 16:20:12.381  INFO 16612 --- [Pool-5-worker-4] .z.j.c.c.ConcurrentHashMapTestController : gap size:-100
2021-11-26 16:20:12.380  INFO 16612 --- [Pool-5-worker-6] .z.j.c.c.ConcurrentHashMapTestController : gap size:100
2021-11-26 16:20:12.383  INFO 16612 --- [io-8080-exec-10] .z.j.c.c.ConcurrentHashMapTestController : finish size:1500
```

可以观察到，除了一开始计算是正确的，后面每个线程都计算出需要填充100个数据，最终执行结果1900不是预期的1000.

针对这个场景，我们可以举一个形象的例子。ConcurrentHashMap 就像是一个大篮子，现在这个篮子里有 900 个桔子，我们期望把这个篮子装满 1000 个桔子，也就是再装 100 个桔子。

有 10 个工人来干这件事儿，大家先后到岗后会计算还需要补多少个桔子进去，最后把桔子装入篮子。ConcurrentHashMap 这个篮子本身，可以确保多个工人在装东西进去时，不会相互影响干扰，

但无法确保工人 A 看到还需要装 100 个桔子但是还未装的时候，工人 B 就看不到篮子中的桔子数量。

更值得注意的是，你往这个篮子装 100 个桔子的操作不是原子性的，在别人看来可能会有一个瞬间篮子里有 964 个桔子，还需要补 36 个桔子。

#### 总结

- 使用了 ConcurrentHashMap，`不代表`对它的`多个操作之间`的`状态是一致`的，`是没有其他线程在操作它的`，如果需要确保需要手动加锁。
- 诸如 `size`、`isEmpty` 和 `containsValue` 等聚合方法，在并发情况下`可能会反映 ConcurrentHashMap 的中间状态`。因此在并发情况下，这些方法的`返回值只能用作参考`，而`不能用于流程控制`。显然，利用 size 方法计算差异值，是一个流程控制。
- 诸如 putAll 这样的聚合方法也不能确保原子性，在 `putAll 的过程中去获取数据可能会获取到部分数据`。

解决方案就是加锁就好了

```java
  @GetMapping("right2")
    public String right() throws InterruptedException {
        ConcurrentHashMap<String, Long> concurrentHashMap = getData(ITEM_COUNT - 100);
        log.info("init size:{}", concurrentHashMap.size());


        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);
        forkJoinPool.execute(() -> IntStream.rangeClosed(1, 10).parallel().forEach(i -> {
            //下面的这段复合逻辑需要锁一下这个ConcurrentHashMap
            synchronized (concurrentHashMap) {
                int gap = ITEM_COUNT - concurrentHashMap.size();
                log.info("gap size:{}", gap);
                concurrentHashMap.putAll(getData(gap));
            }
        }));
        forkJoinPool.shutdown();
        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);
        log.info("finish size:{}", concurrentHashMap.size());
        return "OK";
    }
```

```bash
2021-11-26 16:26:23.640  INFO 21144 --- [nio-8080-exec-6] .z.j.c.c.ConcurrentHashMapTestController : init size:900
2021-11-26 16:26:23.642  INFO 21144 --- [Pool-5-worker-9] .z.j.c.c.ConcurrentHashMapTestController : gap size:100
2021-11-26 16:26:23.643  INFO 21144 --- [ool-5-worker-11] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.643  INFO 21144 --- [Pool-5-worker-6] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.643  INFO 21144 --- [Pool-5-worker-4] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.643  INFO 21144 --- [Pool-5-worker-4] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.644  INFO 21144 --- [ool-5-worker-13] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.644  INFO 21144 --- [Pool-5-worker-2] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.644  INFO 21144 --- [Pool-5-worker-6] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.644  INFO 21144 --- [ool-5-worker-11] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.644  INFO 21144 --- [Pool-5-worker-9] .z.j.c.c.ConcurrentHashMapTestController : gap size:0
2021-11-26 16:26:23.646  INFO 21144 --- [nio-8080-exec-6] .z.j.c.c.ConcurrentHashMapTestController : finish size:1000
```



### 没有充分了解并发工具的特性，从而无法发挥其威力

我们来看一个使用 Map 来统计 Key 出现次数的场景吧，这个逻辑在业务代码中非常常见。

- 使用 ConcurrentHashMap 来统计，Key 的范围是 10。
- 使用最多 10 个并发，循环操作 1000 万次，每次操作累加随机的 Key。
- 如果 Key 不存在的话，首次设置值为 1。

我们吸取之前的教训，直接通过锁的方式锁住 Map，同时使用并行流和并行执行线程池提高速度，然后做判断、读取现在的累计值、加 1、保存累加后值的逻辑。这段代码在功能上没有问题，但无法充分发挥 ConcurrentHashMap 的威力。

这里我们测试三组运行时间

```java
    /**
     * 循环次数
     */
    private static final int LOOP_COUNT = 10000000;
    /**
     * 线程数量
     */
    private static final int THREAD_COUNT = 10;
    /**
     * 元素数量
     */
    private static final int ITEM_COUNT = 10;

    private static void norMaluse() throws InterruptedException {
        ConcurrentHashMap<String, Long> freqs = new ConcurrentHashMap<>(ITEM_COUNT);
        //并行执行的任务框架 将大任务分成若干小任务
        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);
        // rangeClosed()  [1,LOOP_COUNT] 闭区间
        // 使用并行流计算
        forkJoinPool.execute(() -> IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -> {
                    //获得一个随机的Key
                    String key = "item" + ThreadLocalRandom.current().nextInt(ITEM_COUNT);
                    synchronized (freqs) {
                        if (freqs.containsKey(key)) {
                            //Key存在则+1
                            freqs.put(key, freqs.get(key) + 1);
                        } else {
                            //Key不存在则初始化为1
                            freqs.put(key, 1L);
                        }
                    }
                }
        ));
        forkJoinPool.shutdown();
        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);
    }


    public static void main(String[] args) throws InterruptedException {
        long startTime = System.currentTimeMillis();
        norMaluse();
        long endTime = System.currentTimeMillis();
        System.out.println("程序运行时间： " + (endTime - startTime) + "ms");
    }
```

```bash
程序运行时间： 1494ms
程序运行时间： 1455ms
程序运行时间： 1492ms
```
::: tip
 代码改进,利用了下面两点

 - 使用 ConcurrentHashMap 的原子性方法 `computeIfAbsent` 来做复合逻辑操作，判断 Key 是否存在 Value，如果不存在则把 Lambda 表达式运行后的结果放入 Map 作为 Value，也就是新创建一个 `LongAdder` 对象，最后返回 Value。
 - 由于 computeIfAbsent 方法返回的 Value 是 `LongAdder`，是一个`线程安全的累加器`，因此可以直接调用其 `increment` 方法进行累加。
::: 
```java
    /**
     * 关于 computeIfAbsent 的说明
     * // java8之前。从map中根据key获取value操作可能会有下面的操作
     * Object key = map.get("key");
     * if (key == null) {
     *     key = new Object();
     *     map.put("key", key);
     * }
     *
     * // java8之后。上面的操作可以简化为一行，若key对应的value为空，会将第二个参数的返回值存入并返回
     * Object key2 = map.computeIfAbsent("key", k -> new Object());
     *
     * */
    private static Map<String, Long> goodUse() throws InterruptedException {
        // LongAdder 1.8新增的一个原子性操作类
        // 用于解决 高并发的请求下AtomicLong的性能问题
        ConcurrentHashMap<String, LongAdder> freqs = new ConcurrentHashMap<>(ITEM_COUNT);
        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);
        forkJoinPool.execute(() -> IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -> {
                    String key = "item" + ThreadLocalRandom.current().nextInt(ITEM_COUNT);
                    //用computeIfAbsent()方法来实例化LongAdder，然后利用LongAdder来进行线程安全计数
                    freqs.computeIfAbsent(key, k -> new LongAdder()).increment();
                }
        ));
        forkJoinPool.shutdown();
        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);
        //因为我们的Value是LongAdder而不是Long，所以需要做一次转换才能返回
        return freqs.entrySet().stream()
                .collect(Collectors.toMap(
                        e -> e.getKey(),
                        e -> e.getValue().longValue())
                );
    }


    public static void main(String[] args) throws InterruptedException {
        long startTime = System.currentTimeMillis();
        //norMaluse();
        goodUse();
        long endTime = System.currentTimeMillis();
        System.out.println("程序运行时间： " + (endTime - startTime) + "ms");
    }
```

```bash
程序运行时间： 359ms
程序运行时间： 362ms
程序运行时间： 369ms
```
::: tip
 补充说明，computeIfAbsent 为什么如此高效呢？

 主要是因为CAS

 为什么不使用putIfAbsent

 computeIfAbsent和putIfAbsent区别是三点：

 1. 当Key存在的时候，如果Value获取比较昂贵的话，putIfAbsent就白白浪费时间在获取这个昂贵的Value上（这个点特别注意）
 2. Key不存在的时候，putIfAbsent返回null，小心空指针，而computeIfAbsent返回计算后的值
 3. 当Key不存在的时候，putIfAbsent允许put null进去，而computeIfAbsent不能，之后进行containsKey查询是有区别的（当然了，此条针对HashMap，ConcurrentHashMap不允许put null value进去）
::: 


```java
    static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,
                                        Node<K,V> c, Node<K,V> v) {
        return U.compareAndSetObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
    }
```

### 没有认清并发工具的使用场景，因而导致性能问

如果我们要使用 `CopyOnWriteArrayList`，那一定是因为`场景需要`而不是因为足够酷炫。如果`读写比例均衡`或者有`大量写操作`的话，使用 `CopyOnWriteArrayList` 的`性能`会`非常糟糕`。

我们来测试一下`CopyOnWriteArrayList` 和普通加锁方式 `ArrayList` 的读写性能吧

```java
    //测试并发写的性能
    @GetMapping("write")
    public Map testWrite() {
        List<Integer> copyOnWriteArrayList = new CopyOnWriteArrayList<>();
        //ArrayList并不是线程安全的，如果想要做到线程安全，我们可以使用 Collections.synchronizedList
        List<Integer> synchronizedList = Collections.synchronizedList(new ArrayList<>());
        StopWatch stopWatch = new StopWatch();
        int loopCount = 100000;
        stopWatch.start("Write:copyOnWriteArrayList");
        //循环100000次并发往CopyOnWriteArrayList写入随机元素
        //由于高并发下Random这种使用CAS来保证线程安全的类性能低下，ThreadLocalRandom继承自Random用于克服性能问题
        //ThreadLocalRandom正确的使用就是ThreadLocalRandom.current().nextInt()，千万不要把ThreadLocalRandom.current()单独赋值，大家可以自己实际操作一下
        IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -> copyOnWriteArrayList.add(ThreadLocalRandom.current().nextInt(loopCount)));
        stopWatch.stop();
        stopWatch.start("Write:synchronizedList");
        //循环100000次并发往加锁的ArrayList写入随机元素
        IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -> synchronizedList.add(ThreadLocalRandom.current().nextInt(loopCount)));
        stopWatch.stop();
        log.info(stopWatch.prettyPrint());
        Map result = new HashMap();
        result.put("copyOnWriteArrayList", copyOnWriteArrayList.size());
        result.put("synchronizedList", synchronizedList.size());
        return result;
    }

    //帮助方法用来填充List
    private void addAll(List<Integer> list) {
        list.addAll(IntStream.rangeClosed(1, 1000000).boxed().collect(Collectors.toList()));
    }

    //测试并发读的性能
    @GetMapping("read")
    public Map testRead() {
        //创建两个测试对象
        List<Integer> copyOnWriteArrayList = new CopyOnWriteArrayList<>();
        List<Integer> synchronizedList = Collections.synchronizedList(new ArrayList<>());
        //填充数据
        addAll(copyOnWriteArrayList);
        addAll(synchronizedList);
        StopWatch stopWatch = new StopWatch();
        int loopCount = 1000000;
        int count = copyOnWriteArrayList.size();
        stopWatch.start("Read:copyOnWriteArrayList");
        //循环1000000次并发从CopyOnWriteArrayList随机查询元素
        IntStream.rangeClosed(1, loopCount).parallel().forEach(i -> copyOnWriteArrayList.get(ThreadLocalRandom.current().nextInt(count)));
        stopWatch.stop();
        stopWatch.start("Read:synchronizedList");
        //循环1000000次并发从加锁的ArrayList随机查询元素
        IntStream.range(0, loopCount).parallel().forEach(i -> synchronizedList.get(ThreadLocalRandom.current().nextInt(count)));
        stopWatch.stop();
        log.info(stopWatch.prettyPrint());
        Map result = new HashMap(2);
        result.put("copyOnWriteArrayList", copyOnWriteArrayList.size());
        result.put("synchronizedList", synchronizedList.size());
        return result;
    }
```

```bash
---------------------------------------------
ns         %     Task name
---------------------------------------------
6624646100  100%  Write:copyOnWriteArrayList
019955300  000%  Write:synchronizedList

---------------------------------------------
ns         %     Task name
---------------------------------------------
022066600  007%  Read:copyOnWriteArrayList
274392100  093%  Read:synchronizedList
```
::: warning
 大量写的场景（10 万次 add 操作），CopyOnWriteArray 几乎比同步的 ArrayList 慢一百倍：

 而在大量读的场景下（100 万次 get 操作），CopyOnWriteArray 又比同步的 ArrayList 快五倍以上：
::: 
为何在大量写的场景下，CopyOnWriteArrayList 会这么慢呢？

以 add 方法为例，每次 add 时，都会用 Arrays.copyOf 创建一个新数组，频繁 add 时内存的申请释放消耗会很大

```java
    /**
     * Appends the specified element to the end of this list.
     *
     * @param e element to be appended to this list
     * @return {@code true} (as specified by {@link Collection#add})
     */
    public boolean add(E e) {
        synchronized (lock) {
            Object[] elements = getArray();
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements, len + 1);
            newElements[len] = e;
            setArray(newElements);
            return true;
        }
    }
```

